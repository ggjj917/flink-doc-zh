

# 流连接器

## 预定义的源和接收器

Flink内置了一些基本数据源和接收器，并且始终可用。该[预定义的数据源](https://flink.sojb.cn/dev/datastream_api.html#data-sources)包括文件，目录和插座读书，并从摄取集合和迭代器的数据。该[预定义的数据接收器](https://flink.sojb.cn/dev/datastream_api.html#data-sinks)支持写入文件，以输出和错误，并插槽。

## 捆绑连接器

连接器提供用于与各种第三方系统连接的代码。目前支持这些系统：

*   [Apache Kafka](kafka.html)（源/汇）
*   [Apache Cassandra](cassandra.html)（接收器）
*   [亚马逊Kinesis Streams](kinesis.html)（源/汇）
*   [Elasticsearch](elasticsearch.html)（接收器）
*   [Hadoop文件系统](filesystem_sink.html)（接收器）
*   [RabbitMQ](rabbitmq.html)（源/汇）
*   [Apache NiFi](nifi.html)（源/汇）
*   [Twitter Streaming API](twitter.html)（来源）

请记住，要在应用程序中使用其中一个连接器，通常需要其他第三方组件，例如数据存储或消息队列的服务器。另请注意，虽然本节中列出的流连接器是Flink项目的一部分，并且包含在源版本中，但它们不包含在二进制分发版中。可以在相应的小节中找到进一步的说明。

## Apache Bahir中的连接器

Flink的其他流处理连接器正在通过[Apache Bahir](https://bahir.apache.org/)发布，包括：

*   [Apache ActiveMQ](https://bahir.apache.org/docs/flink/current/flink-streaming-activemq/)（源/汇）
*   [Apache Flume](https://bahir.apache.org/docs/flink/current/flink-streaming-flume/)（水槽）
*   [Redis](https://bahir.apache.org/docs/flink/current/flink-streaming-redis/)（水槽）
*   [阿卡](https://bahir.apache.org/docs/flink/current/flink-streaming-akka/)（水槽）
*   [Netty](https://bahir.apache.org/docs/flink/current/flink-streaming-netty/)（来源）

## 其他连接到Flink的方法

### 通过异步I / O进行数据丰富

使用连接器不是将数据输入和输出Flink的唯一方法。一种常见的模式是在一个`Map`或多个`FlatMap` 中查询外部数据库或Web服务以丰富主数据流。Flink提供了一个用于[异步I / O](https://flink.sojb.cn/dev/stream/operators/asyncio.html)的API， 以便更有效，更稳健地进行这种丰富。

### 可查询状态

当Flink应用程序将大量数据推送到外部数据存储时，这可能会成为I / O瓶颈。如果所涉及的数据具有比写入更少的读取，则更好的方法可以是外部应用程序从Flink获取所需的数据。在[可查询的状态](https://flink.sojb.cn/dev/stream/state/queryable_state.html)界面，允许通过Flink被管理的状态，按需要查询支持这个。

